\hypertarget{basic-controls}{%
\section{Basic Controls}\label{basic-controls}}

In the Simulation Chapter, we saw that a parametric curve can be used to
generate a path for a robot. Two issues quickly arise. First, noise,
errors in velocity and path discretization will cause the vehicle to
drift off of the computed path. The formulas continue to drive the robot
as if we are still on the correct trajectory. This is known as
\emph{Open Loop} control. This means there is no feedback from the
sensors to correct for drift, discretization or path error. The drift
will accumulate over time and no matter how accurately you compute the
path, the robot will continue to stray from the path. The only way to
correct the drift is to have some type of feedback in the control code.

The second issue is that a given parametric curve sets velocity as part
of the path. Later in this chapter we will separate the path from
velocity in the parametric functions, but it still leaves no room to
adapt to changes. Just as the position can drift, so can the velocity.
We need feedback for velocity as well. In addition, it is important to
be able to adapt to the environment, for example if we need to slow down
at some point to avoid a collision. So, feedback in our systems turns
out to be essential.

\begin{quote}
Using position feedback as a way to mitigate drift.
\end{quote}

As we discussed in the simulation chapter, the approach to minimize the
drift is to replace the parametric path with a feedback control system
based on sensing the environment. Thus if we missed hitting the target
point in the last segment, we don't use next point in the precomputed
path, but have the controller provide a modified direction, see
\texttt{fig:pathdriftcorrection}. This keeps the robot headed towards
the desired path by using position feedback. A simple stop, rotate to
orient and drive approach will work in very simple applications. How
about an approach that corrects as we drive? When we drive a car, we
continually monitor our position on the road and correct as
needed.\footnote{Texting while driving is an example of open loop
  control. Not looking at the road means you do not use sensor feedback
  to correct the path resulting in a collision.}

\hypertarget{heading-to-goal}{%
\subsection{Heading to Goal}\label{heading-to-goal}}

After driving a few robots around on less than perfect terrain, it is
clear that driving a straight line can be hard. Assuming the goal is
actually driving to a goal and not as much staying on the line, how can
we correct during the route to keep our orientation towards the goal
point? Assume that you know your orientation error,
\texttt{fig:ddorientationerror}.

\begin{quote}
Orientation error of \(\alpha\).
\end{quote}

Recall the alternate form of the differential drive equations:

\[\begin{aligned}
\begin{array}{l}
v = \frac{r}{2} (\dot{\phi_1}+\dot{\phi_2}) \\[3mm]
\dot{\theta} = \frac{r}{2L} (\dot{\phi_1}-\dot{\phi_2}) .
\end{array}
\end{aligned}\]

We are interested in finding wheel velocities such that \(v\) is
constant, \(v_c\) and \(\alpha \to 0\). So we start with wheel
velocities of the form

\[\begin{aligned}
\begin{array}{l}
\dot{\phi_1} = \frac{1}{r} (v_c+Lk\alpha)\\[3mm]
\dot{\phi_2} = \frac{1}{r} (v_c-Lk\alpha)
\end{array}
\end{aligned}\]

This gives us

\[\begin{aligned}
\begin{array}{l}
v = v_c \\[3mm]
\dot{\theta} = k\alpha .
\end{array}
\end{aligned}\]

Assume that the robot is relatively far from the goal with respect to
robot speed. If so, then \(\dot{\beta}\) is small. Since
\(\beta = \omega + \alpha\) it implies that
\(\dot{\alpha} \approx -\dot{\omega}\) and we have

\[\dot{\alpha} = -k\alpha.\]

The solution to this differential equation is

\[\alpha(t) = \alpha(0) e^{-kt}\]

which has \(\alpha(t) \to 0\) as \(t\to 0\) if \(k>0\). Large values of
\(k\) produce fast response times and small values produce slow
response. However, in implementation one works with a discrete (digital)
time controller. Large values can cause the robot to sweep past the
target and oscillate about the goal line. These oscillations can even
grow causing unstable motion. Normally we select small values to start
and observe how well it controls the robot. Increasing \(k\) as needed
when the response is insufficient. Selecting good values of \(k\), known
as the gain, is discussed in the PID control section.

\hypertarget{classical-controls}{%
\subsection{Classical Controls}\label{classical-controls}}

Controls is a large interdisciplinary subject. Many engineers have
expressed the sentiment that robotics and controls are the same subject.
That view is up for debate, however everyone agrees that controls is a
very important aspect to robotics. In the next few sections, we briefly
touch on the topic. We begin with some terms found in the controls
literature.

\begin{itemize}
\tightlist
\item
  Open Loop - device control without using sensor feedback.
\item
  Closed Loop - device control using sensor feedback.
\item
  Bang-Bang (On-off) Control - A control approach that turns the
  actuator or motor completely on or off without using proportional
  values.
\item
  P Control - Proportional control, using the error between the desired
  state and sensed state to control the device.
\item
  PD Control - Proportional-Derivative control, using the error between
  the desired state and sensed state and rate of change of the error to
  control the device.
\item
  PID Control - Proportional-Integral-Derivative control, using the
  error, rate of change of the error and a history of the error to
  control the device.
\end{itemize}

PID is one of the most popular control approaches in industry. It has
wide application due to ease of use and reasonable effectiveness.
Related to PID are PD, PI and P which are just versions of PID where
selected terms are set to zero in the formulas. From holding a
temperature in your house or oven, to cruise control on your car, to
managing flow rates in industrial plants to many more applications,
control systems are an essential aspect to an engineered solution. We
will be using these algorithms to set position, velocity and force in
our robots.

\begin{quote}
Feedback and Control for motor speed.
\end{quote}

\texttt{Fig:motorfeedback} shows the basic feedback loop for controlling
the speed on a motor. We will assume this encoder returns angular
velocity (rpm) although in practice they return a signal which needs to
be translated to rpm. This can be easily done as part of the controller
block. The controller block is the part that takes the two signals,
desired speed and actual speed, and decides what command to give to the
motor driver. The motor driver will then power the motor.

Very little must change in the diagram if we wish to build a servo or
manipulator control system. For a servo, the encoder returns absolute
angle information. If the motor is attached to a mechanical arm, then
the encoder is the device that returns the location of the end-effector.
Most of our discussion below will use motor speed as an example, but
these ideas apply to articulated systems as well.

We will be concerned with three quantities here. First, the desired
configuration, which in \texttt{Fig:motorfeedback} is \(v_d\). Second,
the measured or actual configuration, \(v_m\). And third, the control
signal delivered to the actuator control unit, \(u(t)\).

\hypertarget{bang-bang-control}{%
\subsection{Bang-Bang Control}\label{bang-bang-control}}

Bang-Bang control or On-Off control attempts move the system to the
desired configuration by using a series of on/off signals:

\[\begin{aligned}
u(t) = \left\{ \begin{array}{lr} u_c & \mbox{~if~} v_m(t) < v_d \\  0 & \mbox{~if~} v_m(t)\geq v_d \end{array} \right.
\end{aligned}\]

where \(u_c\) is a constant. When \(v_m < v_d\) a constant power is
applied to the motor. Since the system is digital, the signal is sampled
every \(\Delta t\) seconds. There are also delays in the time required
to run the control algorithm. So, the power will normally be applied
past the point where the motor speed exceeds the desired speed.

In this system, a fixed control effort is used and no attempt at scaling
it based on measured speeds is done. The obvious result is an
oscillation of the actual speed around the set speed,
\texttt{Fig:bangbang}. This approach is fine for systems with slow
dynamics (significant inertial) where one only wants to be close to the
set value; such as house temperature. For higher response systems, this
approach can feel rough as it jumps from off to on and back. It can also
become unstable with very rapid response times.

\begin{quote}
Bang-Bang or On-Off Control.
\end{quote}

We can smooth this out a bit by placing a range for turning on and off
the motor. Assume that \(v_{\mbox{on}} < v_d < v_{\mbox{off}}\) then

\[\begin{aligned}
u(t) = \left\{ \begin{array}{lr} u_c & \mbox{~if~} v_m(t) \leq v_{\mbox{on}}  \\  0 & \mbox{~if~} v_m(t)\geq v_{\mbox{off}} \end{array} \right.   .
\end{aligned}\]

This is not a good velocity or position control system for the robot. We
clearly want to take into account how far off the set value we are and
adjust our control effort. Meaning we want to base our control effort on
the amount of error. This is the approach used with the family of P, PD
and PID controllers described below.

\hypertarget{proportional-control}{%
\subsection{Proportional Control}\label{proportional-control}}

The idea of proportional control is to set the control effort
proportionally to the error, \(e(t) = v_d - v_m\):

\[u(t) = K_P e(t) .\]

This is an intuitive thing to try and in some applications works well. A
proportional control is mathematically more complicated that the Bang
Bang control discussed above. It overcomes some of the issues in on-off
controllers since they can continuously vary their output. The constant
\(K_P\) is known as a gain, in the case the proportional gain. A high
proportional gain results in a large change in the output for a given
change in the error. If the proportional gain is too high, the system
can become unstable, oscillation (like we saw with the On-Off
controller) can occur. In contrast, a small gain results in a small
output response to a large input error, and a less responsive or less
sensitive controller.

\hypertarget{example-of-how-to-use-a-p-controller-to-drive-a-robot-along-a-path}{%
\subsubsection{Example of how to use a p-controller to drive a robot
along a
path}\label{example-of-how-to-use-a-p-controller-to-drive-a-robot-along-a-path}}

In this example, we extend the previous example of holding a fixed
heading. Assume that you have two points \(t_0: (x_0,y_0)\) and
\(t_1: (x_1, y_1)\). If the robot is at the first point with an unknown
orientation, how does one drive the robot to the second point in a
smooth motion? We can define two error terms

\[e_1(t) = \sqrt{(x_1 - x_m)^2 +  (y_1 - y_m)^2},\]

\[e_2(t) = \mbox{atan2}((y_1 - y_m), (x_1 - x_m)) - \theta_m .\]

\(e_1\) measures the difference between current location and goal
location, and \(e_2\) measures the difference between current vehicle
direction and the direction to the goal. We can try a proportional
control on the orientation of the vehicle by proportionally adjusting
the differences in the wheel velocities. Let \(v\) be the base speed.
Then select the speed for the wheels:

\[\dot{\phi}_1 = v + k_1 e_2(t), \quad \dot{\phi}_2 = v - k_1 e_2(t).\]

The robot can move at a fixed speed until it gets close to goal and then
can ramp down the speed by using the \(e_1\) error value. If
\(e_1(t) < d\) then

\[\dot{\phi}_1 = k_2e_1(t)(v + k_1 e_2(t)) , \quad \dot{\phi}_1 = k_2e_1(t)(v - k_1 e_2(t)).\]

The value \(k_2\) can be selected so the speed is continuous across the
\(e_1(t) < d\) jump. Selecting some arbitrary values, \(r=20\),
\(L=12\), \(\Delta t =0.01\), \(k_1=2.0\) and \(k_2=0.2\). \(k_2\) is
selected for continuity on wheel speed. \(k_1\) was derived
experimentally. The start point is (0,0) and endpoint is (40,60). The
result is given in \texttt{Fig:pcontrolDDbot}.

\begin{quote}
A noise free example.
\end{quote}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth,height=\textheight]{ControlFigures/noisepcontrolDDbot.*}
\caption{Adding noise to the wheels.}
\end{figure}

\begin{verbatim}
r = 20.0
l = 12.0
dt  = 0.01
Tend = 6.0
N = int(Tend/dt)

xend = 40
yend = 60
v = 1.0
k1 = 2.0
k2 = 0.2

x = np.zeros(N)
y = np.zeros(N)
th = np.zeros(N)

i= 0
while(i<N-1):
    th_err = atan2(yend - y[i], xend - x[i]) - th[i]
    d1 = abs(x[i] - xend)
    d2 = abs(y[i] - yend)
    w = v
    d = sqrt(d1*d1+d2*d2)
    if (d<0.5):
        break
    if (d > 100):  break
    w1 = w + k1*th_err
    w2 = w - k1*th_err
    if (d<5):
        w1, w2 = k2*d*(w + k1*th_err), k2*d*(w - k1*th_err)
    dx = (r*dt/2.0)*(w1+w2)*cos(th[i])
    dy = (r*dt/2.0)*(w1+w2)*sin(th[i])
    dth = (r*dt/(2.0*l))*(w1-w2)
    x[i+1] = x[i] + dx
    y[i+1] = y[i] + dy
    th[i+1] = th[i] + dth
    i = i+1
\end{verbatim}

A simple modification can take a sequence of points and navigate the
robot along the path of points. Place the points into an array. Set the
counter to the first array index. When the robot is within a small
distance of the goal point, increment the counter. Note that the "small
distance" is a parameter here. It could be the radius of the robot. As
you swithc from one target point to the next, you do not need to slow
the robot down. The controller will adjust the heading.
\texttt{Fig:pcontrolDDbotpath} demonstrates this algorithm.

\begin{quote}
Starting direction \(\theta =0\).
\end{quote}

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth,height=\textheight]{ControlFigures/pcontrolDDbotpath2.*}
\caption{Starting direction \(\theta = \pi /2\).}
\end{figure}

There are two main issues reported with proportional control. The first
is oscillation which can be produced by setting the gain to large. The
second is persistent offset error. This is a constant difference between
the desired value (set point) and the measured value. In some systems,
turning the gain down to avoid oscillations produces higher offset
error. Turing the gain up to remove the offset error introduces or
increases oscillations. These systems may not have a "sweet spot" or
interval of values for which neither issue is presented. So we need
additional machinery to correctly control the system.

You will find that in these path following simulations, you don't often
see the oscillations that plague other systems. So far we have not
included momentum (or other physical aspects) in the simulation. These
are simulations of first order system. Without mass, momentum, etc, we
have full control and so overshoot behavior is not seen in simple
simulations.

\hypertarget{pid-control-overview}{%
\subsection{PID Control Overview}\label{pid-control-overview}}

To address the oscillations, overshoot and instability, we use a more
robust control term, \(u(t)\), that includes the error, the change in
the error and the error history:

\[u(t) = k_P  e(t)  + k_D \frac{de(t)}{dt}  + k_I \int_0^t e(\tau)d\tau\]

\begin{itemize}
\tightlist
\item
  \(e(t)\) - Error \(=v_{des}(t) - v_{act}(t)\)
\item
  \(k_P\) - Proportional gain
\item
  \(k_I\) - Integral gain
\item
  \(k_D\) - Derivative gain
\end{itemize}

\hypertarget{pid---proportional-term}{%
\subsubsection{PID - Proportional Term}\label{pid---proportional-term}}

Within the PID control, the proportional control contributes in the same
manner as it does alone.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth,height=\textheight]{ControlFigures/Change_with_Kp.png}
\caption{Proportional control.}
\end{figure}

\hypertarget{pid---integral-term}{%
\subsubsection{PID - Integral Term}\label{pid---integral-term}}

The contribution from the integral term is proportional to both the
magnitude of the error and the duration of the error. The integral in a
PID controller is the sum of the instantaneous error over time and gives
the accumulated offset that should have been corrected previously. The
accumulated error is then multiplied by the integral gain (\(k_i\)) and
added to the controller output.

The integral term accelerates the movement of the process towards
setpoint and eliminates the residual steady-state error that occurs with
a pure proportional controller. However, since the integral term
responds to accumulated errors from the past, it can cause the present
value to overshoot the setpoint value. This is known as integrator
windup.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth,height=\textheight]{ControlFigures/Change_with_Ki.png}
\caption{Proportional-Integral control.}
\end{figure}

\hypertarget{pid---derivative-term}{%
\subsubsection{PID - Derivative Term}\label{pid---derivative-term}}

The derivative of the process error is calculated by determining the
slope of the error over time and multiplying this rate of change by the
derivative gain \(k_d\). The magnitude of the contribution of the
derivative term to the overall control action is termed the derivative
gain, \(k_d\). The derivative term slows the rate of change of the
controller output. Derivative control is used to reduce the magnitude of
the overshoot produced by the integral component and improve the
combined controller-process stability. However, the derivative term
slows the transient response of the controller.

Also, differentiation of a signal amplifies noise and thus this term in
the controller is highly sensitive to noise in the error term, and can
cause a process to become unstable if the noise and the derivative gain
are sufficiently large.

\begin{figure}
\centering
\includegraphics[width=0.4\textwidth,height=\textheight]{ControlFigures/Change_with_Kd.png}
\caption{Proportional-Integral-Derivative control.}
\end{figure}

\hypertarget{pi-control-discretization}{%
\subsubsection{PI Control
Discretization}\label{pi-control-discretization}}

Set \(K_D=0\)

\[u(t) = k_P  e(t) + k_I \int_0^t e(\tau)d\tau\]

Use of the controllers in a computer requires discretization. Let
\(t_n\) be the discrete times, \(\Delta t\) the time step,
\(e_n = e(t_n)\), and \(U_n = u(t_n)\). The discrete form can be
converted to a basic recursion:

\[U_n = k_P e_n + k_I \Delta t \sum_{i=1}^n \frac{e_i + e_{i-1}}{2}\]

\[U_n - U_{n-1} = k_P(e_n - e_{n-1}) + k_I \Delta t \left( \frac{e_n + e_{n-1}}{2}\right)\]

\[U_n = U_{n-1} + K_P(e_n - e_{n-1}) + K_I (e_n + e_{n-1})\]

where \(K_P = k_p\), \(K_I = k_I \Delta t  / 2\).

\hypertarget{pd-control-discretization}{%
\subsubsection{PD Control
Discretization}\label{pd-control-discretization}}

\[u(t) = k_P e(t) + k_D \frac{de(t)}{dt}\]

The expression can be converted into a recursive relation:

\[U_n  = k_P e_n + k_D \frac{e_n - e_{n-1}}{\Delta t}\]

\[U_n - U_{n-1} = k_P(e_n - e_{n-1}) + k_D \frac{e_n - 2e_{n-1} +e_{n-2}}{\Delta t}\]

\[U_n = U_{n-1} + K_P(e_n - e_{n-1}) + K_D (e_n - 2e_{n-1} +e_{n-2})\]

where \(K_P = k_p\), \(K_D = k_D / \Delta t\).

\hypertarget{pid-control-discretization}{%
\subsubsection{PID Control
Discretization}\label{pid-control-discretization}}

\[u(t) = k_P e(t) + k_I \int_0^t e(\tau)d\tau + k_D \frac{de(t)}{dt}\]

In a similar fashion as above, the expression can be converted into a
recursive relation:

\[U_n  = k_P e_n + k_I \Delta t \sum_{i=1}^n \frac{e_i + e_{i-1}}{2}  + k_D \frac{e_n - e_{n-1}}{\Delta t}\]

\[U_n - U_{n-1} = k_P(e_n - e_{n-1}) + k_I \Delta t \left( \frac{e_n + e_{n-1}}{2}\right)  + k_D \frac{e_n - 2e_{n-1} +e_{n-2}}{\Delta t}\]

\[U_n = U_{n-1} + K_P(e_n - e_{n-1}) + K_I (e_n + e_{n-1}) + K_D (e_n - 2e_{n-1} +e_{n-2})\]

where \(K_P = k_p\), \(K_I = k_I \Delta t  / 2\),
\(K_D = k_D / \Delta t\).

\hypertarget{pid-application}{%
\subsection{PID Application}\label{pid-application}}

For this example, we want to control our differential drive robot to
follow a path. Assume the path is given by a list of close points
\((x_n, y_n)\) for \(0 \leq n \leq N\). As before we are interested in
finding wheel velocities such that \(v\) is constant, \(v_c\), and we
are driving from point to point. Recall the differential drive
equations:

\[\begin{aligned}
\begin{array}{l}
v = \frac{r}{2} (\dot{\phi_1}+\dot{\phi_2}) \\[3mm]
\dot{\theta} = \frac{r}{2L} (\dot{\phi_1}-\dot{\phi_2}) .
\end{array}
\end{aligned}\]

We will use a PID control approach to control the wheel velocities so we
can closely track the path defined by the points. Using the same
structure we assume wheel velocities of the form

\[\begin{aligned}
\begin{array}{l}
\dot{\phi_1} = \frac{1}{r} (v_c+Lu(t))\\[3mm]
\dot{\phi_2} = \frac{1}{r} (v_c-Lu(t))
\end{array}
\end{aligned}\]

where \(u(t)\) is obtained from a PID control strategy. In practice on a
computer this would use the discrete form of the PID control:

\[\begin{aligned}
\begin{array}{l}
\omega_{1,n} = \frac{1}{r} (v_c+LU_n)\\[3mm]
\omega_{2,n} = \frac{1}{r} (v_c-LU_n)
\end{array}
\end{aligned}\]

Since \(U_n\) is a function of the error \(e_n\), we need to figure out
what we want for error. The idea is to head to \(n\)-th point in the
list until we are within some neighborhood of the point, then we
increment the counter \(n\) meaning target the following point. This
requires control on the heading like the example that started our
controls journey, but we cannot assume the points are far away, so we
need to track position and angles.

Assuming you have your current location as \((x,y)\) and target location
\((x_n,y_n)\), the required heading would be
\(\left\langle x_n -x, y_n - y \right\rangle\). If you have a compass on
the robot, then you know the current heading. The heading error we used
before is

\[e_n =  \mbox{atan2}( x_n - x , y_n - y) - \theta_n .\]

What if you don't have a compass? The current heading can be estimated
by \(\left\langle x-x_{n-1} , y - y_{n-1}\right\rangle\) which is just
an estimate of the derivative. And we have

\[e_n =  \mbox{atan2}( x_n - x , y_n - y) - \mbox{atan2}( x-x_{n-1} , y - y_{n-1}) .\]

Up to this point we have computed the heading error without discussion.
Specifically the approach has been to take the current heading vector
and compute the heading angle via atan2, then subtract from the desired
heading (which might have also been computed via atan2). This gives
formulas that look like atan2(vy,vx) - atan2(uy,ux).

\hypertarget{example}{%
\subsubsection{Example:}\label{example}}

\begin{itemize}
\item
  For ux = 0.8, uy = 0.5 and vx = 1.1, vy = -.2\\
  then atan2(vy,vx) - atan2(uy,ux) \(\approx\) -0.73845 .
\item
  For ux = -0.8, uy = 0.5 and vx = -1.1, vy = -.2\\
  then atan2(vy,vx) - atan2(uy,ux) \(\approx\) -5.544732 .
\end{itemize}

If you graph these, the pair of vectors are reflections about the y-axis
and so should give the same result. What is the issue? The sum of those
two appears to be \(-2\pi\). Not surprisingly the problem lies in the
ambiguity of which angle is desired. From calculus we know that the
angle between two vectors can be determined by the dot product.

\[u \cdot v = \cos(\theta) \| u\| \|v\|  \quad \rightarrow\quad  \theta = \cos^{-1} \left(\frac{u \cdot v }{ \| u\| \|v\|}\right) .\]

It is worthwhile to write a function that correctly determines the
signed angle between vectors. Using the cross product:

\begin{verbatim}
def angle(u1, u2, v1, v2):
   n1 = math.sqrt(u1*u1+u2*u2)
   n2 = math.sqrt(v1*v1+v2*v2)
   dot = u1*v1+u2*v2
   cross = u1*v2 - v1*u2
   if cross == 0.0:  return 0.0
   if cross > 0:  sign = 1
   if cross < 0:  sign =-1
   theta = sign*math.acos(dot/(n1*n2))
   return theta
\end{verbatim}

Returning to the control problem we have:

\[\begin{aligned}
\begin{array}{l}
e_n=  \mbox{angle}( \cos(\theta_n), \sin(\theta_n), x_n - x , y_n - y )\\[3mm]
U_n = U_{n-1} + K_P(e_n - e_{n-1}) + K_I (e_n + e_{n-1}) + K_D (e_n - 2e_{n-1} +e_{n-2})\\[3mm]
\omega_{1,n} = \frac{1}{r} (v_c+LU_n)\\[3mm]
\omega_{2,n} = \frac{1}{r} (v_c-LU_n)
\end{array}
\end{aligned}\]

The last aspect is to work out the transition to the next point. Assume
you want to get within \(\delta\) of the point. This means that you want
to drive to \((x_n, y_n)\) until

\[d = \sqrt{(x-x_n)^2 + (y - y_n)^2} < \delta\]

then increment \(n\) to switch to the new point. If you are using the
non-compass formula, you will want save your location when you switch.
Using the saved location instead of \((x_{n-1}, y_{n-1})\) will give you
better heading accuracy.

\hypertarget{pid-parameter-tuning}{%
\subsection{PID Parameter Tuning}\label{pid-parameter-tuning}}

Tuning a PID control can be a bit of an art. There are a number of
approaches in the literature and we provide two below. The first tuning
method has you work the gains like dials starting with the proportional
gain, the addressing the derivative gain and finishing with the integral
gain.

\begin{enumerate}
\tightlist
\item
  Select a typical operating setting for the desired speed, turn off
  integral and derivative parts. Increase \(K_P\) to maximum or until
  oscillation occurs.
\item
  If system oscillates, divide \(K_P\) by 2.
\item
  Increase \(K_D\) and observe behaviour when increasing or decreasing
  the desired speed by 5\%. Select a value of \(K_D\) which gives a
  damped response.
\item
  Slowly increase \(K_I\) until oscillation starts. Then divide \(K_I\)
  by 2 or 3.
\item
  Check overall controller performance under typical conditions.
\end{enumerate}

\hypertarget{pid-parameter-tuning-ziegler-nichols-method}{%
\subsubsection{PID Parameter Tuning: Ziegler-Nichols
method}\label{pid-parameter-tuning-ziegler-nichols-method}}

Another heuristic tuning method is formally known as the Ziegler
-Nichols method, introduced by John G. Ziegler and Nathaniel B. Nichols
in the 1940s. As in the method above, the \(K_i\) and \(K_d\) gains are
first set to zero. The P gain is increased until it reaches the ultimate
gain, \(K_u\), at which the output of the loop starts to oscillate.
\(K_u\) and the oscillation period \(T_u\) are used to set the gains as
shown in \texttt{tab:ZieglerNicholsmethod}

\begin{quote}
\begin{longtable}[]{@{}llll@{}}
\toprule
\begin{minipage}[b]{0.18\columnwidth}\raggedright
Control Type\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
\(K_p\)\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\raggedright
\(K_i\)\strut
\end{minipage} & \begin{minipage}[b]{0.25\columnwidth}\raggedright
\(K_d\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.18\columnwidth}\raggedright
P\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\(0.50K_u\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\begin{itemize}
\tightlist
\item
\end{itemize}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\begin{itemize}
\tightlist
\item
\end{itemize}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
PI\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\(0.45K_u\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\(T_u/1.2\)\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\begin{itemize}
\tightlist
\item
\end{itemize}\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
PD\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\(0.8K_u\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\begin{itemize}
\tightlist
\item
\end{itemize}\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\(T_u / 1.2\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.18\columnwidth}\raggedright
PID\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\(0.60K_u\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\raggedright
\(T_u/2\)\strut
\end{minipage} & \begin{minipage}[t]{0.25\columnwidth}\raggedright
\(T_u / 8\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}
\end{quote}

\hypertarget{velocity-and-position-control}{%
\subsection{Velocity and Position
Control}\label{velocity-and-position-control}}

When working with robot arms and vehicles, it is rarely safe to jump
from one speed to another (or one force to another). Safety of the
humans and the system requires that changes in the system state be
controlled. Clearly a robot arm that jumps from one position to another
is dangerous. As would an autonomous vehicle which skidded off from the
light. It is also hard on the mechanical systems to have this form of
bang-bang control applied to changes in set points. For vehicles, high
wheel torques can cause slip and slide which introduces errors in the
navigation.

This is addressed by having speed ramp functions to control the
transition to new set points. This is no more than what we all do in our
cars by slowly pressing down on the accelerator until we reach the
desired speed. \texttt{fig:speedramp0} shows one sample ramp function.
There are times when one needs coordinated control between multiple
devices. This is necessary with any vehicle that has more than one drive
motor, for example a differential drive, \texttt{fig:speedramp1}.

\begin{quote}
A speed ramp function for a single motor

Coordinating two motors separately with a P controller.
\end{quote}

Ramping up each motor to the same speed does not assure straight motion.
Variations between ramp ups can cause significant errors in orientation
for differential drive. Both motors must be ramped up in the same manner
so must be fed the same ramp up function, \texttt{fig:speedramp2}. This
can be done with a P, PI or PID control; a PID version is shown in
\texttt{fig:speedramp3}.

\begin{quote}
Coordinating two motors with the same ramp function.

Coordinating two motors with dual P/PI/PID controllers.
\end{quote}

\hypertarget{kinematics-vs-physics-engine}{%
\subsection{Kinematics vs Physics
Engine}\label{kinematics-vs-physics-engine}}

Kinematics is concerned with the geometry of motion. It describes the
geometry based on the constraints of motion without concerns for the
causes of the motion such as the forces acting on the system. A physics
engine models the forces and the subsequent motion. A kinematics
simulation has no knowledge of mass, inertia, friction, momentum and
accelerations. It is possible to have jumps in velocity, which would
correspond to infinite forces/accelerations. A physics engine will
provide a more realistic simulation at the cost of increased
computation. This includes the control strategy and so in practice you
may not be able achieve the desired control due to limits on forces
available.

\textbf{Footnotes}
